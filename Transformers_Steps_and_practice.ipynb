{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dsfJU2Gf-rm2"
   },
   "source": [
    "# **Steps (Transformer basic coding steps)**\n",
    "1. Get tokens (input_ids, attention_mask, labels) from pre-trained model's tokenizer. You use a pre-trained tokenizer (like BERT‚Äôs) to convert raw text into tokens.\n",
    "\n",
    "```\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    tokens = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "```\n",
    "2. Convert these tokens into a tensor dataset. Combine input_ids, attention_mask, and labels into a TensorDataset.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "from torch.utils.data import TensorDataset\n",
    "dataset = TensorDataset(tokens[\"input_ids\"], tokens[\"attention_mask\"], torch.tensor(labels))\n",
    "\n",
    "```\n",
    "3. Load the tensor dataset using DataLoader. This allows batching and shuffling.\n",
    "\n",
    "\n",
    "```\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "```\n",
    "4. Call the pre-trained model. You load the pre-trained Transformer model and fine-tune it.\n",
    "\n",
    "\n",
    "```\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFFfhU3S_b-1"
   },
   "source": [
    "5. Wrap in a class (if using PyTorch MLP-style)\n",
    "\n",
    "  This step is optional but helpful if you want to customize or mimic the traditional PyTorch training structure.\n",
    "\n",
    "  If you're not modifying the architecture (just fine-tuning), you can use the prebuilt Hugging Face model directly.\n",
    "\n",
    "6. Select optimizer, loss function\n",
    "\n",
    "```\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "```\n",
    "7. Train the model\n",
    "\n",
    "\n",
    "```\n",
    "model.train()\n",
    "for batch in train_loader:\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    loss = criterion(outputs.logits, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "```\n",
    "8. Evaluate the model. After training, switch to model.eval() and turn off gradients\n",
    "\n",
    "\n",
    "```\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        preds = outputs.logits.argmax(dim=1)\n",
    "\n",
    "```\n",
    "9. Test using a user-defined function. You can define a predict(text) function that tokenizes and runs through model.eval().\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8amo9EbdAU1q"
   },
   "source": [
    "üü® Optional: Hugging Face‚Äôs Trainer skips manual loops\n",
    "You don‚Äôt have to write your own training loop unless you want control. Hugging Face provides:\n",
    "\n",
    "\n",
    "```\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "```\n",
    "\n",
    "So basic tranformer's code working is\n",
    "1. Get tokens (input_ids, attention_mask, labels) from pre trained model\n",
    "2. Convert these tokens into tensor dataset\n",
    "3. Load the tensor dataset using DataLoader\n",
    "4. Call the pretrained model\n",
    "5. write the basic MLP work flow like we did in spam classification using BERT, in a class\n",
    "6. Then call this class, select optimizer, loss function\n",
    "7. train the model (model.train)\n",
    "8. Evaluate the model\n",
    "9. Test using some user defined function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Do3KBpB0AL_a"
   },
   "source": [
    "| Model Type              | Same Steps?   | Key Differences                                                               |\n",
    "| ----------------------- | ------------- | ----------------------------------------------------------------------------- |\n",
    "| **BERT**                | ‚úÖ Yes         | Input: `input_ids`, `attention_mask`, often used for classification           |\n",
    "| **GPT-2**               | ‚ö†Ô∏è Not always | No `attention_mask` sometimes, used for **text generation**; uses causal mask |\n",
    "| **T5 / BART**           | ‚ö†Ô∏è Partly     | Have **encoder-decoder**, used for **translation/summarization**              |\n",
    "| **RoBERTa, DistilBERT** | ‚úÖ Yes         | Same as BERT, just lighter or trained differently                             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ij6oyWf5v0Yf"
   },
   "source": [
    "# Problem Statement: **Social Media Monitoring for COVID-19 Insights using BERT**\n",
    "\n",
    "### A company is launching a social media monitoring system to identify tweets related to COVID-19, aiming to track trends, misinformation, and public sentiment. Your task is to fine-tune a pre-trained BERT model using PyTorch to classify whether a given tweet is about COVID-19 or not.\n",
    "\n",
    "**References:**\n",
    "\n",
    "1. **Attention is All you Need:** [Click Here](https://arxiv.org/abs/1706.03762)\n",
    "\n",
    "2. **BERT:** [Click Here](https://arxiv.org/abs/1810.04805)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EvRmT5FwULP"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbmeJcDWuCHn"
   },
   "source": [
    "Imports and CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "faxxMOzMMa5O",
    "outputId": "03ee43b9-aeb9-4795-ee3c-b1df66c76b1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Check if CUDA (GPU) is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-J7ECFzwVpH"
   },
   "source": [
    "**Step1:** Dataset Overview\n",
    "\n",
    "* We use **covid_twitter_dataset_codebasics_DL** dataset which has 5287 rows.\n",
    "* Columns: ID, text and target\n",
    "* The feature column (text) contains the tweet content, and the target column (target) contains the binary labels indicating whether a tweet is COVID-19-related (**1**) or not (**0**).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "IspKKeW0MpRw",
    "outputId": "73b1d152-a682-43c1-f239-9fa76b7a34d7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5287,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5287,\n        \"samples\": [\n          \"train_2705\",\n          \"train_632\",\n          \"train_85\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5287,\n        \"samples\": [\n          \"kitchen Lmao I always do during Ramadan\",\n          \"Welcome back I hope you will consider our future relationship with China as a priority\",\n          \"New upload python nbxmpp 0 9 95 20020429 5303bb12 1 by Martin into experimental\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-18bce1e9-9356-43f7-99fd-7e605286cbbd\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>The bitcoin halving is cancelled due to</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>MercyOfAllah In good times wrapped in its gran...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>266 Days No Digital India No Murder of e learn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>India is likely to run out of the remaining RN...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>In these tough times the best way to grow is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18bce1e9-9356-43f7-99fd-7e605286cbbd')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-18bce1e9-9356-43f7-99fd-7e605286cbbd button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-18bce1e9-9356-43f7-99fd-7e605286cbbd');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-6775f4ec-24f3-495c-a54e-ee4aa81f155a\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6775f4ec-24f3-495c-a54e-ee4aa81f155a')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-6775f4ec-24f3-495c-a54e-ee4aa81f155a button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "        ID                                               text  target\n",
       "0  train_0            The bitcoin halving is cancelled due to       1\n",
       "1  train_1  MercyOfAllah In good times wrapped in its gran...       0\n",
       "2  train_2  266 Days No Digital India No Murder of e learn...       1\n",
       "3  train_3  India is likely to run out of the remaining RN...       1\n",
       "4  train_4  In these tough times the best way to grow is t...       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/content/covid_twitter_dataset_codebasics_DL.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1W_rVH5qw_fY",
    "outputId": "e62977fa-51a3-4683-e986-2b34d1508fce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5287 entries, 0 to 5286\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      5287 non-null   object\n",
      " 1   text    5287 non-null   object\n",
      " 2   target  5287 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 124.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DA54uIDayjAC"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxju6d9xxpai"
   },
   "source": [
    "**Step2:** Split the dataset\n",
    "\n",
    "* Train:Test :: 70:30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4jxmEQZyj8H"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "7utLzhlnWHvR",
    "outputId": "f0b663d7-2d90-4c1d-bfe6-5025723f81a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "target\n",
       "0    2746\n",
       "1    2541\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "RjHDhskFM2Tk",
    "outputId": "04a79273-52db-4463-be55-f7ff23501ad4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3846</th>\n",
       "      <td>Update Total cases 3 017 766 12 879 Current ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>so turns out my cat hasn t been home since lat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>Wait what Ramadan goes on for weeks Nobody men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>I really love watching Man v Food vs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>MercyOfAllah There is flexibility within the r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> object</label>"
      ],
      "text/plain": [
       "3846    Update Total cases 3 017 766 12 879 Current ca...\n",
       "3257    so turns out my cat hasn t been home since lat...\n",
       "2932    Wait what Ramadan goes on for weeks Nobody men...\n",
       "3139                 I really love watching Man v Food vs\n",
       "1669    MercyOfAllah There is flexibility within the r...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(data.text, data.target, test_size=0.3, random_state=42)\n",
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "KvbJjUjPWh7X",
    "outputId": "2c92ae4f-2703-4629-b3a1-6f23e8983617"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3846</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "3846    1\n",
       "3257    0\n",
       "2932    0\n",
       "3139    0\n",
       "1669    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "NbMkCBwhWlA_",
    "outputId": "9ef4012c-fc32-4668-855b-675f14fc51a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "target\n",
       "0    1932\n",
       "1    1768\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "E07lOuGvWoh5",
    "outputId": "81679381-56aa-4d9c-937a-c8d6c8ca9e0e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "target\n",
       "0    814\n",
       "1    773\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyPCL_kJXitE"
   },
   "source": [
    "1. Split the data set\n",
    "2. call the tokenizer\n",
    "3. create tokenizer function\n",
    "\n",
    "\n",
    "```\n",
    "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "  def tokenize_function(text, labels):\n",
    "\n",
    "      encodings = tokenizer(text, truncation=True, padding='max_length', max_length=128, return_tensors = 'pt')\n",
    "\n",
    "      return encodings['input_ids'],encodings['attention_mask'], torch.tensor(labels, dtype=torch.float)\n",
    "```\n",
    "\n",
    "\n",
    "4. Create dataset from the above\n",
    "\n",
    "\n",
    "```\n",
    "  train_input_ids,train_attention_mask, train_labels = tokenize_function(X_train.values.tolist(), y_train.values.tolist())\n",
    "  \n",
    "  val_input_ids,val_attention_mask, val_labels = tokenize_function(X_test.values.tolist(), y_test.values.tolist())\n",
    "\n",
    "  train_dataset = torch.utils.data.TensorDataset\n",
    "  (train_input_ids, train_attention_mask, train_labels)\n",
    "\n",
    "  val_dataset = torch.utils.data.TensorDataset(val_input_ids, val_attention_mask, val_labels)\n",
    "```\n",
    "\n",
    "\n",
    "5. Modelling\n",
    "\n",
    "  \n",
    "\n",
    "```\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert.config.hidden_size\n",
    "\n",
    "class SentimentClassifier(nn.Module):\n",
    "def __init__(self):\n",
    "  super().__init__()\n",
    "  self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "  for param in self.bert.parameters():\n",
    "\n",
    "    param.requires_grad = False\n",
    "\n",
    "  self.classifier = nn.Sequential(\n",
    "\n",
    "      nn.Linear(self.bert.config.hidden_size, 256),\n",
    "\n",
    "      nn.ReLU(),\n",
    "\n",
    "      nn.Dropout(0.3),\n",
    "\n",
    "      nn.Linear(256, 1),\n",
    "\n",
    "      nn.Sigmoid()\n",
    "  )\n",
    "\n",
    "def forward(self, input_ids, attention_mask):\n",
    "\n",
    "  outputs = self.bert(input_ids=input_ids,\n",
    "  \n",
    "  attention_mask=attention_mask)\n",
    "  \n",
    "  sentence_embedding = outputs.last_hidden_state[:,0,:]\n",
    "  \n",
    "  return self.classifier(sentence_embedding)\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeR071x6yxY9"
   },
   "source": [
    "**Step3:** Tokenization\n",
    "\n",
    "* The AutoTokenizer from the Hugging Face library is used to load the pre-trained BERT tokenizer (bert-base-cased).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269,
     "referenced_widgets": [
      "55bea566fe584cb2b228759ef8e302dd",
      "bd7ba9d286604248a862470d8c52f15d",
      "957f0df4e058470db6a660b7be5ea790",
      "58ee73c6c4f449efb02b1e8334ca8a85",
      "4ee7476b93724c658ee9ee362f4df1b9",
      "8bf1cd361746466fbc7991028d06f834",
      "c89923564093407c887fad281c7785fd",
      "f1ff62b3717a47ef99ba78e57f0bf4f2",
      "66b1f14977cc4be2ae2e81976e9c2281",
      "e801356764a34e99a7759f30d3370e58",
      "64699653c87d4a0b807f55eb3f9b7b19",
      "27d5987837d94832ba4721d3b2b455f9",
      "33c928e967224a7eab8570c5630d4f62",
      "e665ded560cb4bc69840ed88379ca9f6",
      "0c24c8b3cfee431a9fea1d0bfb254de4",
      "d79cc2828e8c4db38b522a77e88433a7",
      "b5dcad55a8544ddeb5d8737beecb9fd8",
      "ec01f44478294bafb28a34774c5e896a",
      "13f4e4ce74ec479f851f252aeaa7aff2",
      "f92e7b3d604e45959c87534f930e2c40",
      "71fd999d6b9547699eaa6ce2f453e2d9",
      "c155ae9618514fd3b2607152ab1cd7d0",
      "2fedbe96e2b94b76bc4aba43a498b6d8",
      "02e03c3569e8473e94bfc0cf1a27d433",
      "49db63a9bac64be786ea3924d6957ab2",
      "af9db2325d5b43d8b4bd0541e3a0c032",
      "6d131df33a8b4227acd7bb498e671e72",
      "163c00d2dbcb4c4dbfd7d1c6152be5b5",
      "5abf2ee5b8f942e1b735d49c006cdcac",
      "37cedb9e456949be9529cb77523abf29",
      "75778d94988a46369b5c27d4ec7eefa1",
      "259d598290ee4d0bb903673487c5a129",
      "4e37d7bc3c9b467ab6c382d2a50b2d11",
      "004e302fb544411698497a05c15db4f0",
      "be0c8975a51643fa8225c44ac75d45fa",
      "9357c2cbc9ad4f838c220df5d612d8e6",
      "91cda6fcfb0e4a069e4e03e5f7a7fae4",
      "1bc296aa74db46968899c19a046eae7b",
      "859159b1230746b487cb6819cfd88859",
      "5d0efbc19dce46b2b409b79f8a6ffbaf",
      "a0a98c12605046bf889bce4439ac6eaa",
      "009874fa342d40288909f4791b703c6b",
      "d91ab82b0b6b425f8c7a3182feeb36a7",
      "a98c68ab37644b7b87d708e699c35a9b"
     ]
    },
    "id": "JnG8WHNENEgf",
    "outputId": "9aaf77a8-3f38-4f59-b831-de820c23993b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55bea566fe584cb2b228759ef8e302dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d5987837d94832ba4721d3b2b455f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fedbe96e2b94b76bc4aba43a498b6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004e302fb544411698497a05c15db4f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CoseMt4eYZd3"
   },
   "source": [
    "Get tokens from tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TXVgSTHqNX_c"
   },
   "outputs": [],
   "source": [
    "train_tokens = tokenizer(list(train_X), padding = True, truncation=True)\n",
    "test_tokens = tokenizer(list(test_X), padding = True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-W2a_y9Nj6d",
    "outputId": "6008a146-c711-4025-a2cf-4c1c55d061af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9_-UV6_eNmhO",
    "outputId": "aaecd682-0617-4b21-91bf-23f20f776ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 3725, 9216, 8653, 2740, 124, 5187, 1559, 5465, 1545, 1367, 5966, 1580, 9493, 2740, 122, 5539, 1571, 26516, 4859, 1545, 4735, 1116, 21606, 5117, 1477, 3993, 1604, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[CLS] Update Total cases 3 017 766 12 879 Current cases 1 915 580 856 Deaths 207 722 468 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "print(train_tokens['input_ids'][0])\n",
    "print(tokenizer.decode(train_tokens['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFf6B70IcRk0"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vCUvn0CcSfZ"
   },
   "source": [
    "**Step4**: Create a dataset class\n",
    "* Implement a custom TokenData class inheriting from torch.utils.data.Dataset.\n",
    "* Use the train argument to toggle between training (train_tokens, train_Y) and testing datasets (test_tokens, test_Y).\n",
    "* Define __len__ to return the dataset length and __getitem__ to provide tokenized inputs (input_ids, attention_mask) and labels (labels) as tensors.\n",
    "* Ensure the class works correctly by retrieving a sample and verifying the output format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rI1s_tixN6Cy"
   },
   "outputs": [],
   "source": [
    "class TokenData(Dataset):\n",
    "    def __init__(self, train = False):\n",
    "        if train:\n",
    "            self.text_data = train_X\n",
    "            self.tokens = train_tokens\n",
    "            self.labels = list(train_Y)\n",
    "        else:\n",
    "            self.text_data = test_X\n",
    "            self.tokens = test_tokens\n",
    "            self.labels = list(test_Y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {}\n",
    "        for k, v in self.tokens.items():\n",
    "            sample[k] = torch.tensor(v[idx])\n",
    "        sample['labels'] = torch.tensor(self.labels[idx])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBonK0IScVF8"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unRFzzTecV62"
   },
   "source": [
    "**Step5**: Create Dataloaders\n",
    "\n",
    "* Initialize the `TokenData` class to create train_dataset and test_dataset objects for training and testing datasets.\n",
    "* Set `batch_size=30` and enable shuffling for the training dataset to improve model generalization.\n",
    "* Verify that train_loader and test_loader correctly return batches of tokenized inputs and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sr5VRe0kN9Ub"
   },
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "# Pass True to the train parameter for the training dataset\n",
    "train_dataset = TokenData(train=True)\n",
    "# Pass False (or rely on the default) for the test dataset\n",
    "test_dataset = TokenData(train=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewX-Bqb9caOv"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZT2z96dcYUg"
   },
   "source": [
    "**Step6:** Define Model\n",
    "*  Use `BertForSequenceClassification` with `bert-base-cased` to load a pre-trained BERT model for sequence classification tasks.\n",
    "* Use `AdamW` optimizer with a learning rate of `1e-5` to fine-tune the model parameters. This optimizer is well-suited for transformer-based models.\n",
    "* Use `CrossEntropyLoss` to compute the loss for multi-class classification (as the dataset contains two classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fRvsF9oJOCBh",
    "outputId": "4fac863f-3f91-4faa-d4ee-1e330987bc03"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_model =  BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=2)\n",
    "optimizer = optim.AdamW(bert_model.parameters(), lr=1e-05)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3U1ees-cbgA"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhJGyZjxccZa"
   },
   "source": [
    "* num_eochs = 3\n",
    "* Use bert_model.to(device) to move the model to a GPU if available, or keep it on the CPU. This ensures efficient computation, especially for large datasets or models like BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J1QoUC-8OOvG",
    "outputId": "ca5df62b-fc54-41c5-99a4-dddd3390c9e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "bert_model.to(device) # Transfer model to GPU if available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7weERW42ckLw"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UY0aqY4Qcf_y"
   },
   "source": [
    "**Step7:** Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yN-7EqSpOZvB",
    "outputId": "35d09576-b38b-402c-973a-50cac0e4e9b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Training Loss: 0.4742\n",
      "Epoch 2/3 - Training Loss: 0.2177\n",
      "Epoch 3/3 - Training Loss: 0.1283\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    bert_model.train()\n",
    "    total_train_loss = 0.0  # Initialize total loss for each epoch\n",
    "\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # Set gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Pass data to the model\n",
    "        outputs = bert_model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "\n",
    "        # Get logits and calculate the loss\n",
    "        pred = outputs.logits\n",
    "        loss = loss_fn(pred, batch['labels'])\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimizing model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss for the epoch\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    # Calculate and log the average loss for the epoch\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - Training Loss: {avg_train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JuK0Fa9ocle6"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aj8C8_-RcmQI"
   },
   "source": [
    "**Step8:** Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TK-wiYwBVeNx",
    "outputId": "07252c95-9808-4dc2-efc7-4ade533f8e27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[748  66]\n",
      " [101 672]]\n",
      "Test Set - Loss: 0.2906, Accuracy: 89.48%\n"
     ]
    }
   ],
   "source": [
    "# Set model to evaluation mode\n",
    "bert_model.eval()\n",
    "\n",
    "# Variables for tracking accuracy and loss\n",
    "correct = 0\n",
    "total = 0\n",
    "total_test_loss = 0.0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Disable gradient computation during testing\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = bert_model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "\n",
    "        # Get logits\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(logits, batch['labels'])\n",
    "        total_test_loss += loss.item()\n",
    "\n",
    "        # Get predictions\n",
    "        preds = logits.argmax(dim=1)\n",
    "\n",
    "        # Update the correct count and total number of samples\n",
    "        correct += (preds == batch['labels']).sum().item()\n",
    "        total += batch['labels'].size(0)\n",
    "\n",
    "        # Store predictions and labels for confusion matrix\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch['labels'].cpu().numpy())\n",
    "\n",
    "# Calculate the average test loss\n",
    "avg_test_loss = total_test_loss / len(test_loader)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = 100 * correct / total\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Print overall results\n",
    "print(f\"Test Set - Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WN_IoRS1Fcqx"
   },
   "source": [
    "**BONUS**: Visualize the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "QRVFfhtQfc-S",
    "outputId": "1ebb60b6-1590-47b7-c81e-681d07a77bc5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtBWNt8ZEu_1"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fxk8JzEWLJvh"
   },
   "source": [
    "**Step9**: Inference with new Tweets\n",
    "\n",
    "* Run this inference code to predict the output for test_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qIV_feNNLO9X",
    "outputId": "6a913d10-096a-4dcf-b012-c12c11759e90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Tweet Predictions:\n",
      "\n",
      "Tweet: The number of COVID-19 cases has increased in the past week.\n",
      "Prediction: COVID-related\n",
      "Confidence: 98.26%\n",
      "--------------------------------------------------\n",
      "\n",
      "Tweet: Just watched an amazing sunset at the beach!\n",
      "Prediction: Not COVID-related\n",
      "Confidence: 91.99%\n",
      "--------------------------------------------------\n",
      "\n",
      "Tweet: New vaccination centers are opening up to combat the spread of coronavirus.\n",
      "Prediction: COVID-related\n",
      "Confidence: 96.46%\n",
      "--------------------------------------------------\n",
      "\n",
      "Tweet: A virus has impacted the global ecosystem a lot\n",
      "Prediction: COVID-related\n",
      "Confidence: 98.13%\n",
      "--------------------------------------------------\n",
      "\n",
      "Tweet: India lost the match againt Australia at Adelaide\n",
      "Prediction: Not COVID-related\n",
      "Confidence: 71.89%\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test tweets\n",
    "test_tweets = [\n",
    "    \"The number of COVID-19 cases has increased in the past week.\",\n",
    "    \"Just watched an amazing sunset at the beach!\",\n",
    "    \"New vaccination centers are opening up to combat the spread of coronavirus.\",\n",
    "    \"A virus has impacted the global ecosystem a lot\",\n",
    "    \"India lost the match againt Australia at Adelaide\"\n",
    "]\n",
    "\n",
    "# Predict function for a single tweet\n",
    "def predict_tweet(tweet_text):\n",
    "    # Tokenize\n",
    "    tokens = tokenizer(tweet_text, padding=True, truncation=True, return_tensors='pt')\n",
    "    tokens = {k: v.to(device) for k, v in tokens.items()}\n",
    "\n",
    "    # Predict\n",
    "    bert_model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**tokens)\n",
    "        probs = torch.softmax(outputs.logits, dim=1)\n",
    "        prediction = torch.argmax(probs, dim=1)\n",
    "\n",
    "    return {\n",
    "        'text': tweet_text,\n",
    "        'is_covid': bool(prediction.item()),\n",
    "        'confidence': probs[0][prediction[0]].item() * 100\n",
    "    }\n",
    "\n",
    "# Make predictions for test tweets\n",
    "print(\"Sample Tweet Predictions:\\n\")\n",
    "for tweet in test_tweets:\n",
    "    result = predict_tweet(tweet)\n",
    "    print(f\"Tweet: {result['text']}\")\n",
    "    print(f\"Prediction: {'COVID-related' if result['is_covid'] else 'Not COVID-related'}\")\n",
    "    print(f\"Confidence: {result['confidence']:.2f}%\")\n",
    "    print(\"-\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4JZGv2Mfj0t"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
